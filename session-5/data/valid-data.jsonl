{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nLessons from 13 months of entrepreneurship\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "It\u2019s been 13 months since I had a W2 job... \n\nDuring this time, I\u2019ve realized there are several popular misconceptions about entrepreneurship. \n\nHere are a few that are top of mind for me right now \ud83d\udc47 \n\n\u274c \"I need funding to build a business.\" \n\u2705 The vast majority of businesses take no outside funding, and <1% take VC. Figuring out how to survive IS the game. \n\n\u274c \"I need an idea that can scale well.\" \n\u2705 \u201dDo things that don\u2019t scale\u201d -Paul Graham. There\u2019s no point in scaling something no one wants. IF demand exists, then there\u2019s always a way to scale. \n\n\u274c \"I need to learn web development frameworks to build a SaaS product.\" \n\u2705 \u201dBuild with the tech you know\u201d -Peiter Levels. The key is speed. You don\u2019t have six months to take a bootcamp. Learn what you need to solve the problem.\n\n--\nMedia: Image"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nDon\u2019t build a chatbot and 5 LLM use case ideas.\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "Don\u2019t use AI to build a chatbot \ud83e\udd16 \n\n\u274c Although ChatGPT (and friends) has captured the world\u2019s imagination regarding AI, the business value of building an \"AI chatbot\" may not justify the cost. \n\nHere are 5 better LLM use cases for business \ud83d\udc47 \n\n1) Structure unstructured data\u2014format data from inconvenient sources into a structured database \n\n2) Standardize data\u2014resolve conflicts between databases and make it analytics-ready \n\n3) Data augmentation\u2014enrich existing datasets with meta-tags and other information \n\n4) Data generation\u2014create synthetic datasets for developing custom AI solutions \n\n5) Semantic search\u2014improve existing search functions using text embeddings \ud83e\udd14 \n\nWhat am I missing here? \n\n#LLM #AI #datascience\n\n--\nMedia: None"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\n10 AI buzzwords explained\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "AI seems to be riddled with buzzwords these days. \n\nHere are 10 common AI terms every practitioner should know... \n\n1) RAG = automatically providing relevant context (i.e. docs) to an AI system so it can generate better responses\n2) Vector DB = numerical representations of documents which can be used for RAG and search \n3) Fine-tuning = adapting a model to a particular use case through additional training \n4) AI Agent = an AI system that can plan and execute tasks \n5) Evals = tests that score an AI system\u2019s efficacy \n6) Hallucination = a \"made-up\" response from an AI that sounds reasonable \n7) Multimodal = data of different formats (e.g. text, images, audio, videos, tables, time series) \n8) Small Language Models = LLMs with ~1B parameters \n9) Quantization = reducing the precision of model parameters to reduce its size \n10) Distillation = using a large model to train a smaller one \n\n\u2014\n\n What's missing from this list?\n\n--\nMedia: Notes screenshot"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nHow I\u2019ve continued learning after grad school and sharing upcoming TDE event with content creator panel\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "Here\u2019s my \u201csecret\u201d for continuing to learn after grad school: content creation \ud83e\udd2b \n\nWriting an article, making a YouTube video, or even posting on LinkedIn is a great way to force yourself to deepen your understanding of a topic. \n\nHowever, making that first post isn\u2019t always so easy \ud83d\ude05 \n\nThis Saturday (Dec 16) at 11AM CST, I\u2019ll be sitting down with top data creators from Medium, YouTube, and LinkedIn for a panel discussion on the upsides and challenges of content creation. \n\nA big thank you to Dmytro Iakubovskyi, Keith Galli, and Matthew Blasa for being part of this discussion \u2764\ufe0f \n\nJoin us live and ask these panelists your content creation questions \ud83d\udc47 \n\n\ud83d\udc49 Register here: https://lu.ma/2o16dhzz \n\n#event #datascience #contentcreation\n\n--\nMedia: Event link"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nEvolution of OCR and sharing YouTube video on multimodal AI\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "5 years ago, sentiment analysis and OCR required specialized ML skills. \n\nToday, however, these are trivially done by off-the-shelf AI systems... \n\nModels like GPT-4o and LLaMA 3.2 Vision can seamlessly process text and image data. \n\nThis combination is important because text inputs provide users with an interface to readily adapt the model's behavior to endless NLP and CV tasks. \n\nFor example, reading scanned invoices, defect detection, chart analysis, coding apps based on design mockups, visual question answering, and much more. \n\nIn my latest YouTube video, I shared how to use LLaMA 3.2 Vision (locally) to perform various bespoke CV tasks. \n\nCheck it out here \ud83d\udc47 \n\nhttps://lnkd.in/gFXJAPB6\n\n--\nMedia: Image"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nSharing LLM compression blog post\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "Large language models (LLMs) demonstrate impressive performance across a wide range of tasks. \n\nHowever, their immense scale can make deploying them in real-world settings a challenge \ud83d\ude2e\u200d\ud83d\udca8 \n\nIn my latest blog post, I discuss how to mitigate these challenges using model compression. \n\nModel compression seeks to reduce an ML model\u2019s size without sacrificing performance. \n\nI review 3 types of compression techniques (i.e. Quantization, Pruning, and Knowledge Distillation) and walk through an example implementation in Python. \n\nCheck it out and let me know what you think \ud83d\udc47\n\n--\nMedia: Blog link"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nUsing polars for the first time\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "I finally found an excuse to try polars (thanks to Ben for showing me the light). \n\nFor the uninitiated, polars is essentially a (much) faster version of pandas. \ud83d\udc3b\u200d\u2744\ufe0f > \ud83d\udc3c \n\nAfter using it for a recent project, here are 3 things I liked about it \ud83d\udc47 \n\n1) The Syntax \n\nMost of the syntax is identical to pandas, which made it super easy to use without any tutorials. \n2) The \u201cLazy\u201d API This allows you to manipulate dataframes without loading them into memory. \n\nAt the end, you can perform all the operations via the .collect() method. \n3) .scan_parquet() \n\nYes, you can import .parquet files in pandas, but when combined with the Lazy API, this allows you to locally work with 10X bigger datasets in polars than pandas\n\n--\nMedia: Code"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nMultimodal RAG and its value. Share blog post\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "Two major topics in AI this year were multimodal models and RAG. \n\nBut\u2026 what if we brought these ideas together? Multimodal RAG systems are capable of processing text and non-text data. \n\nThis enables more powerful solutions beyond what is conveyed by text alone. \n\nFor example, it could analyze someone\u2019s facial expressions and speech tonality to give a richer context to a meeting\u2019s transcription. \n\nIn my latest blog post, I give a beginner-friendly guide to Multimodal RAG and share an example implementation using LLaMA 3.2 Vision and CLIP. \n\nCheck it out here \ud83d\udc47 \n\nhttps://lnkd.in/grY5bGDz\n\n--\nMedia: Article screenshot"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nGetting a data science job was hard until I learned these 5 things\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "Getting a Data Science Job was hard until I learned these 5 things \ud83d\udc47 \n\n1. Adapt your resume to the specific role \n\nYou have about 7 seconds of a hiring manager's attention when reviewing your resume; use it to call out all the skills they listed in the job description. \n\n2. Do real-world projects \n\nWhile toy projects from class or Kaggle are a great way to learn, hiring managers care about real-world impact. \n\n3. Make a portfolio \n\nDespite the free no-code tools for making a portfolio website, most people don't make one. That makes this a super easy way to stand out. \n\n4. Stay out of the weeds (unless they ask) \n\nThis was one of my greatest struggles. When someone asked about a project, I would dive right into the technical details. \n\nThis is the best way to lose someone's attention (even data scientists). \n\n5. Be yourself (not who you think they want to hire) \n\nWhen I interviewed for my full-time data science role, I dove into a rant about my love for optimization. \n\nMost people get confused and awkward when I discuss such topics, but not the interviewers. They got pumped up... that's when I knew I found my people \ud83d\ude01 \n\nWhat was an unlock for you when applying to data science roles?\n\n--\nMedia: Image"}]}
{"messages": [{"role": "system", "content": "LinkedIn Post Writer for Shaw Talebi, AI educator and entrepreneur"}, {"role": "user", "content": "Write a LinkedIn post based on the following idea:\nAI won\u2019t make you rich\u2026 solving problems will\n\nInclude:\n- A compelling opening line that hooks the reader\n- Copy that expands upon the idea in valuable way\n- A call to action or share relevant content\n\nOutput:\n"}, {"role": "assistant", "content": "AI won\u2019t make you rich\u2026 solving problems will. \n\nOver the past year, I\u2019ve seen a trend of CEOs and founders scrambling to find AI use cases for their businesses. \n\nWhile this AI excitement is great for data scientists like me, it is not sufficient for value generation. \n\nIn other words, \u201cusing AI\u201d won\u2019t necessarily move the needle on the things important to businesses. \n\nFor that, one must solve problems\u2026 which may not require a chatbot, RAG system, or any state-of-the-art AI model. \n\nMore often than not, using readily available AI assistants (e.g., ChatGPT) and having good data infrastructure will get businesses 80% there.\n\n--\nMedia: Image"}]}
